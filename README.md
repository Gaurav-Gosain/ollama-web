# Simple Ollama HTML WebUI ðŸª„

This is a simple web UI for Ollama, a local LLM running on your machine.

> [!NOTE]
> This repository is just an experiment

## Usage

It is a self contained single html file, no need to install anything.

Just open the index.html file in your browser!

> [!NOTE]
> Assumes you have Ollama installed on your machine and
> the ollama server running on the default port.
> Also assumes cross origin requests are allowed.
> Refer to the [Ollama docs](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-allow-additional-web-origins-to-access-ollama)
> for more information and to [setup the correct environment variables for
> Ollama based on your
> platform.](https://github.com/ollama/ollama/blob/main/docs/faq.md#how-can-i-allow-additional-web-origins-to-access-ollama)

## Features

- List available models
- Prompt the models
- Stream responses

## Contributing

Contributions are welcome!

## License

This project is licensed under the MIT License. See the [LICENSE](LICENSE) file
for details.
